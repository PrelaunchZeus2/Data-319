{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> DATA 319: Model-based and Data-based Methods for Data Analytics. Summer 2024 </h2>\n",
    "<h3> Problem Set 1 </h3>\n",
    "<h3> Group <i> (Insert your group number here) </i></h3>\n",
    "<h3> Type students' names <i> (only those who contributed to the group work)</i> here</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. In your own words, provide a definition or description for each of the following (and explain how they are different for the pairs of items):\n",
    "\n",
    "##### (a) Scatterplot vs Hexagon plot\n",
    "    Scatter plots are 2 dimensional plots where data points are represented by (x,y) coordinate pairs on a plane. The hexagon plot is similar to scatter plot but it addresses the problem of having too many points very close to each other. Instead the plane is tiled into hexagonal bins and the bin is color coded to repreesent how many points fall in it.\n",
    "\n",
    "##### (b) Marginal distribution vs Conditional distribution\n",
    "    A marginal distribution describes an outcome independent of other outcomes (i.e probability that x happens) a conditional distribution describes the probabilitty of an event happening based on a different event happening (i.e. probability of x happening if y happened [X | Y])\n",
    "\n",
    "##### (c) Probability mass function vs Probability density function\n",
    "    A probability mass function is used to describe discrete variables. If you are tossing a coin you will always get a whole integer number of outcomes, you cannot get 1.2 heads. The Probability Density Function is used to describe continuous variables where values can fall on any number in a range.\n",
    "\n",
    "##### (d) Statistical independence\n",
    "    Statistical independence means that two variable's outcomes have absolutely no effect on each other.\n",
    "\n",
    "##### (e) Simpson's paradox\n",
    "    Simpson's paradox describes the situation where examining groups of data can produce trends that disappear or are contradictory to the trends that appear when examining the data as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. In your own words, provide brief responses to the following:\n",
    "\n",
    "##### (a) What problem was MapReduce introduced to solve?\n",
    "    Map Reduce was introduced to solve the problem of processing very large data sets with limited bandwidth. MapReduce allows for parallel processing meaning multiple clusters of data can be queued and processed at the same time.\n",
    "##### (b) What are the differences between the Map and Reduce steps?\n",
    "    The Map step first reads all of the data and creates keys for the values, then it groups the data by the keys. The Reduce step then groups, counts, or aggregates the data based on the keys created.\n",
    "##### (c) What is skew in MapReduce?\n",
    "    Skew in MapReduce is what happens when there is an uneven distribution of data resulting in some keys having more values than others. This has an effect on the performance of the map reduce function because it means some tasks take longer than others.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Consider the two dimensional random variable (X, Y) with probability distribution given by:\n",
    "\n",
    "| X/Y | 0 | 1 | \n",
    "|:-:|:-:|:-:|\n",
    "| **0** | 0 | .20 |\n",
    "| **1** | .15 | .10 |\n",
    "| **2** | .25 | .30 |\n",
    "\n",
    "##### (a) Compute the marginal distributions of X and Y.\n",
    "x: 0 = 0.4          y:  0 = 0.20\n",
    "   1 = 0.6              1 = 0.25\n",
    "                        3 = 0.55\n",
    "\n",
    "##### (b) Compute the expected values and variances of X and Y.\n",
    "E(x) = 0(.35) + 1 (.60) = .60\n",
    "E(y) = 0(.20) + 1(.25) + 2(.55) = 1.35 \n",
    "##### (c) Compute the covariance of X and Y using the joint distribution.\n",
    "    E(XY) - E(X) * E(Y)\n",
    "    0.7 - 0.60 * 1.35 = -0.11\n",
    "\n",
    "##### (d) What is the distribution of X conditioned on Y=1?\n",
    "    x: 0 = 0.33\n",
    "       1 = 0.16\n",
    "       2 = 0.50\n",
    "\n",
    "##### (e) Fill in the values *a-f* below so that the new distribution has the same marginals as X and Y but the resulting variables are independent:\n",
    "\n",
    "| X/Y | 0 | 1 | \n",
    "|:-:|:-:|:-:|\n",
    "| **0** |*a*|*d*|\n",
    "| **1** |*b*|*e*|\n",
    "| **2** |*c*|*f*|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal X: 0    0.4\n",
      "1    0.6\n",
      "dtype: float64\n",
      "Marginal Y: 0    0.20\n",
      "1    0.25\n",
      "2    0.55\n",
      "dtype: float64\n",
      "E(x): 0.6000000000000001\n",
      "E(y): 1.35\n",
      "E(XY): 0.7\n",
      "Cov(X, Y): -0.11000000000000021\n",
      "Conditional Distribution of X given Y=1:\n",
      " 0    0.333333\n",
      "1    0.166667\n",
      "2    0.500000\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#PART A - C\n",
    "joint_dist = pd.DataFrame({\n",
    "    '0': [0, .15, .25],\n",
    "    '1': [.20, .10, .30]\n",
    "}, index=['0', '1', '2'])\n",
    "\n",
    "Marginal_dist_X = joint_dist.sum(axis=0)\n",
    "Marginal_dist_Y = joint_dist.sum(axis=1)\n",
    "E_X = np.sum(Marginal_dist_X.index.astype(float) * Marginal_dist_X)\n",
    "E_Y = np.sum(Marginal_dist_Y.index.astype(float) * Marginal_dist_Y)\n",
    "\n",
    "E_XY = np.sum(joint_dist.values * np.outer(joint_dist.index.astype(float), joint_dist.columns.astype(float)))\n",
    "\n",
    "cov_XY = E_XY - E_X * E_Y\n",
    "\n",
    "print(f'Marginal X: {Marginal_dist_X}\\nMarginal Y: {Marginal_dist_Y}\\nE(x): {E_X}\\nE(y): {E_Y}\\nE(XY): {E_XY}\\nCov(X, Y): {cov_XY}')\n",
    "#PART D\n",
    "joint_prob_X_Y1 = joint_dist['1']\n",
    "marginal_prob_Y1 = Marginal_dist_X['1']\n",
    "conditional_dist_X_given_Y1 = joint_prob_X_Y1 / marginal_prob_Y1\n",
    "\n",
    "print(\"Conditional Distribution of X given Y=1:\\n\", conditional_dist_X_given_Y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Load in the Los Angeles Air Quality (LA_AQ) dataset.\n",
    "\n",
    "##### (a) Construct all of the pairwise scatterplots for the variables of the dataset.\n",
    "\n",
    "##### (b) Compute sample means, covariances, and correlations of these variables.\n",
    "\n",
    "##### (c) Create heatmaps for the covariances and correlations from part (b) separately. Which of these two heatmaps is more informative/useful? Why?  What do you observe about these visualiations?\n",
    "\n",
    "##### (d) Report any interesting findings from your exploratory numerical and visual analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_AQ = pd.DataFrame(pd.read_csv('LA_AQ.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Design a MapReduce algorithm to take a very large file of integers as input and produce as output the average of all the integers. You do not have to write any code or implement your algorithm, just describe the method you would use in detail. \n",
    "\n",
    "##### Assume that the file of integers is stored in a .csv file. Suppose that this large (so large, 13 whole numbers! &#x1F600;) file of integers looks like this:\n",
    "> `9 10 25 9 36 10 42` <br>\n",
    "> `10 9 45 36 10 9`\n",
    "##### That is the file consists of multiple lines (chunks), and each chunk has a big sequence of integers. You may want to assign each chunk to a separate Mapper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Make a copy of CoLab 1 here: https://colab.research.google.com/drive/1S8fagR15E5XK8v8ZIx3QP8p7CHuxy82X?usp=sharing and determine which letter is at the beginning of the most words in the provided dataset.\n",
    "\n",
    "##### The letter that appears at the beginning of the most words in the dataset is \"*TYPE_YOUR_ANSWER*\" (appears *TYPE_YOUR_ANSWER* many times)\n",
    "\n",
    "##### *Please save your CoLab code as a Jupyter notebook (.ipynb) and as a .html file and submit them separately on Canvas.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
