{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> DATA 319: Model-based and Data-based Methods for Data Analytics. Summer 2024 </h2>\n",
    "<h3> Problem Set 1 </h3>\n",
    "<h3> Group <i> (Insert your group number here) </i></h3>\n",
    "<h3> Type students' names <i> (only those who contributed to the group work)</i> here</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. In your own words, provide a definition or description for each of the following (and explain how they are different for the pairs of items):\n",
    "\n",
    "##### (a) Scatterplot vs Hexagon plot\n",
    "    Scatter plots are 2 dimensional plots where data points are represented by (x,y) coordinate pairs on a plane. The hexagon plot is similar to scatter plot but it addresses the problem of having too many points very close to each other. Instead the plane is tiled into hexagonal bins and the bin is color coded to repreesent how many points fall in it.\n",
    "\n",
    "##### (b) Marginal distribution vs Conditional distribution\n",
    "    A marginal distribution describes an outcome independent of other outcomes (i.e probability that x happens) a conditional distribution describes the probabilitty of an event happening based on a different event happening (i.e. probability of x happening if y happened [X | Y])\n",
    "\n",
    "##### (c) Probability mass function vs Probability density function\n",
    "    A probability mass function is used to describe discrete variables. If you are tossing a coin you will always get a whole integer number of outcomes, you cannot get 1.2 heads. The Probability Density Function is used to describe continuous variables where values can fall on any number in a range.\n",
    "\n",
    "##### (d) Statistical independence\n",
    "    Statistical independence means that two variable's outcomes have absolutely no effect on each other.\n",
    "\n",
    "##### (e) Simpson's paradox\n",
    "    Simpson's paradox describes the situation where examining groups of data can produce trends that disappear or are contradictory to the trends that appear when examining the data as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. In your own words, provide brief responses to the following:\n",
    "\n",
    "##### (a) What problem was MapReduce introduced to solve?\n",
    "    Map Reduce was introduced to solve the problem of processing very large data sets with limited bandwidth. MapReduce allows for parallel processing meaning multiple clusters of data can be queued and processed at the same time.\n",
    "##### (b) What are the differences between the Map and Reduce steps?\n",
    "    The Map step first reads all of the data and creates keys for the values, then it groups the data by the keys. The Reduce step then groups, counts, or aggregates the data based on the keys created.\n",
    "##### (c) What is skew in MapReduce?\n",
    "    Skew in MapReduce is what happens when there is an uneven distribution of data resulting in some keys having more values than others. This has an effect on the performance of the map reduce function because it means some tasks take longer than others.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Consider the two dimensional random variable (X, Y) with probability distribution given by:\n",
    "\n",
    "| X/Y | 0 | 1 | \n",
    "|:-:|:-:|:-:|\n",
    "| **0** | 0 | .20 |\n",
    "| **1** | .15 | .10 |\n",
    "| **2** | .25 | .30 |\n",
    "\n",
    "##### (a) Compute the marginal distributions of X and Y.\n",
    "x: 0 = 0.4          y:  0 = 0.20\n",
    "   1 = 0.6              1 = 0.25\n",
    "                        3 = 0.55\n",
    "\n",
    "##### (b) Compute the expected values and variances of X and Y.\n",
    "E(x) = 0(.35) + 1 (.60) = .60\n",
    "E(y) = 0(.20) + 1(.25) + 2(.55) = 1.35 \n",
    "##### (c) Compute the covariance of X and Y using the joint distribution.\n",
    "    E(XY) - E(X) * E(Y)\n",
    "    0.7 - 0.60 * 1.35 = -0.11\n",
    "\n",
    "##### (d) What is the distribution of X conditioned on Y=1?\n",
    "    x: 0 = 0.33\n",
    "       1 = 0.16\n",
    "       2 = 0.50\n",
    "\n",
    "##### (e) Fill in the values *a-f* below so that the new distribution has the same marginals as X and Y but the resulting variables are independent:\n",
    "\n",
    "| X/Y | 0 | 1 | \n",
    "|:-:|:-:|:-:|\n",
    "| **0** |*0.08*|*0.12*|\n",
    "| **1** |*0.1*|*0.15*|\n",
    "| **2** |*0.22*|*0.33*|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal X: 0    0.4\n",
      "1    0.6\n",
      "dtype: float64\n",
      "Marginal Y: 0    0.20\n",
      "1    0.25\n",
      "2    0.55\n",
      "dtype: float64\n",
      "E(x): 0.6000000000000001\n",
      "E(y): 1.35\n",
      "E(XY): 0.7\n",
      "Cov(X, Y): -0.11000000000000021\n",
      "Conditional Distribution of X given Y=1:\n",
      " 0    0.333333\n",
      "1    0.166667\n",
      "2    0.500000\n",
      "Name: 1, dtype: float64\n",
      "      0     1\n",
      "0  0.08  0.12\n",
      "1   0.1  0.15\n",
      "2  0.22  0.33\n"
     ]
    }
   ],
   "source": [
    "##Code For Above\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#PART A - C\n",
    "joint_dist = pd.DataFrame({\n",
    "    '0': [0, .15, .25],\n",
    "    '1': [.20, .10, .30]\n",
    "}, index=['0', '1', '2'])\n",
    "\n",
    "Marginal_dist_X = joint_dist.sum(axis = 0)\n",
    "Marginal_dist_Y = joint_dist.sum(axis = 1)\n",
    "E_X = np.sum(Marginal_dist_X.index.astype(float) * Marginal_dist_X)\n",
    "E_Y = np.sum(Marginal_dist_Y.index.astype(float) * Marginal_dist_Y)\n",
    "\n",
    "E_XY = np.sum(joint_dist.values * np.outer(joint_dist.index.astype(float), joint_dist.columns.astype(float)))\n",
    "\n",
    "cov_XY = E_XY - E_X * E_Y\n",
    "\n",
    "print(f'Marginal X: {Marginal_dist_X}\\nMarginal Y: {Marginal_dist_Y}\\nE(x): {E_X}\\nE(y): {E_Y}\\nE(XY): {E_XY}\\nCov(X, Y): {cov_XY}')\n",
    "#PART D\n",
    "joint_prob_X_Y1 = joint_dist['1']\n",
    "marginal_prob_Y1 = Marginal_dist_X['1']\n",
    "conditional_dist_X_given_Y1 = joint_prob_X_Y1 / marginal_prob_Y1\n",
    "\n",
    "print(\"Conditional Distribution of X given Y=1:\\n\", conditional_dist_X_given_Y1)\n",
    "#PART E\n",
    "marginal_dist_X = joint_dist.sum(axis = 1)\n",
    "marginal_dist_Y = joint_dist.sum(axis = 0)\n",
    "ind_dist = pd.DataFrame(index = joint_dist.index, columns = joint_dist.columns)\n",
    "for x in ind_dist.index:\n",
    "    for y in ind_dist.columns:\n",
    "        ind_dist.loc[x, y] = marginal_dist_X[x] * marginal_dist_Y[y]\n",
    "print(ind_dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Load in the Los Angeles Air Quality (LA_AQ) dataset.\n",
    "\n",
    "##### (a) Construct all of the pairwise scatterplots for the variables of the dataset.\n",
    "    See Below\n",
    "\n",
    "##### (b) Compute sample means, covariances, and correlations of these variables.\n",
    "    See Below\n",
    "\n",
    "##### (c) Create heatmaps for the covariances and correlations from part (b) separately. Which of these two heatmaps is more informative/useful? Why?  What do you observe about these visualiations?\n",
    "    The Correlation Heatmap is far more useful than the covariance heatplot because it shows the relationship between the two variables. Other than the diagonal line of 1 correlation that shows our variables correlating with themselves which is not useful, It is helpful and easy to see which variables might be influencing each other based on the color of the cell. For instance we can see that there is a fairly strong correlation between the CO and NO columns, and a lack of a correlation between the Solar Radiation and NO2 Columns\n",
    "\n",
    "##### (d) Report any interesting findings from your exploratory numerical and visual analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'LA_AQ.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m LA_AQ \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLA_AQ.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#Load Data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#Part A\u001b[39;00m\n\u001b[1;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mpairplot(LA_AQ)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'LA_AQ.csv'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "LA_AQ = pd.DataFrame(pd.read_csv(r'LA_AQ.csv')) #Load Data\n",
    "\n",
    "#Part A\n",
    "sns.pairplot(LA_AQ)\n",
    "plt.show()\n",
    "\n",
    "#Part B\n",
    "mean = LA_AQ.mean()\n",
    "cov = LA_AQ.cov()\n",
    "corr = LA_AQ.corr()\n",
    "print(f'Means:\\n{mean}\\n\\nCovariances:\\n{cov}\\n\\nCorrelations:\\n{corr}')\n",
    "\n",
    "#Part C\n",
    "sns.heatmap(cov, annot = true, fmt='.2f')\n",
    "plt.title('Covariance Heatmap')\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(corr, annot = true, fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Design a MapReduce algorithm to take a very large file of integers as input and produce as output the average of all the integers. You do not have to write any code or implement your algorithm, just describe the method you would use in detail. \n",
    "\n",
    "##### Assume that the file of integers is stored in a .csv file. Suppose that this large (so large, 13 whole numbers! &#x1F600;) file of integers looks like this:\n",
    "> `9 10 25 9 36 10 42` <br>\n",
    "> `10 9 45 36 10 9`\n",
    "##### That is the file consists of multiple lines (chunks), and each chunk has a big sequence of integers. You may want to assign each chunk to a separate Mapper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Make a copy of CoLab 1 here: https://colab.research.google.com/drive/1S8fagR15E5XK8v8ZIx3QP8p7CHuxy82X?usp=sharing and determine which letter is at the beginning of the most words in the provided dataset.\n",
    "\n",
    "##### The letter that appears at the beginning of the most words in the dataset is \"*TYPE_YOUR_ANSWER*\" (appears *TYPE_YOUR_ANSWER* many times)\n",
    "\n",
    "##### *Please save your CoLab code as a Jupyter notebook (.ipynb) and as a .html file and submit them separately on Canvas.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
